{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":10212367,"sourceType":"datasetVersion","datasetId":6311983}],"dockerImageVersionId":30886,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n        ","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-02-27T06:50:39.215533Z","iopub.execute_input":"2025-02-27T06:50:39.215851Z","iopub.status.idle":"2025-02-27T06:50:39.223683Z","shell.execute_reply.started":"2025-02-27T06:50:39.215822Z","shell.execute_reply":"2025-02-27T06:50:39.223012Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# 150 Bi-TCN + AM LR","metadata":{}},{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport tensorflow as tf\nfrom tensorflow.keras.models import Model\nfrom tensorflow.keras.layers import (\n    Input, Conv1D, BatchNormalization, Dropout, ReLU, Flatten, Add, Dense, Lambda, Multiply\n)\nfrom tensorflow.keras.optimizers import Adam\nfrom sklearn.model_selection import train_test_split, StratifiedKFold\nfrom sklearn.preprocessing import LabelEncoder, StandardScaler\nfrom sklearn.linear_model import LassoCV\nfrom sklearn.metrics import (\n    accuracy_score, precision_score, recall_score, f1_score, confusion_matrix, roc_auc_score\n)\nimport time\nimport matplotlib.pyplot as plt\nfrom tqdm import tqdm  # Progress bar\n\n# Load dataset\ndf = pd.read_csv('/kaggle/input/har-dataset/Human_Activity_Recognition_Using_Smartphones_Data.csv')\n\n# Encode target labels\nlabel_encoder = LabelEncoder()\ndf['Activity'] = label_encoder.fit_transform(df['Activity'])\n\n# Separate features and target\nX = df.drop(columns=['Activity']).values\ny = df['Activity'].values\n\n# Feature Scaling\nscaler = StandardScaler()\nX_scaled = scaler.fit_transform(X)\n\nimport warnings\nwarnings.filterwarnings(\"ignore\", category=UserWarning)\n\n# Feature Selection using LASSO\nlasso = LassoCV(cv=5, random_state=42)\nlasso.fit(X_scaled, y)\n\n# Extract absolute coefficients from the best alpha model\nfeature_importance = np.abs(lasso.coef_)\n\n# Get feature names\nfeature_names = df.drop(columns=[\"Activity\"]).columns\n\n# Select top 150 features based on importance\nsorted_idx = np.argsort(feature_importance)[::-1][:150]  # Select top 150 features \nselected_features = np.array(feature_names)[sorted_idx]\nnum_features = len(selected_features)  # Get number of selected features\n\n# Print the number of selected features\nprint(f\"Number of features used for model training: {num_features}\")\n\n# Select corresponding columns from scaled dataset\nX_selected = X_scaled[:, sorted_idx]\n\n# Train-test split\nX_train, X_test, y_train, y_test = train_test_split(X_selected, y, test_size=0.2, random_state=42)\n\n# Reshape for Bi-TCN input\nX_train = X_train[..., np.newaxis]\nX_test = X_test[..., np.newaxis]\n\n# Define Bi-TCN Residual Block with Dilated Convolutions\ndef bi_residual_block(x, filters, dilation_rate):\n    \"\"\"Bidirectional TCN Residual Block\"\"\"\n    # Forward Conv1D\n    forward = Conv1D(filters=filters, kernel_size=3, padding='causal', dilation_rate=dilation_rate)(x)\n    forward = BatchNormalization()(forward)\n    forward = ReLU()(forward)\n    forward = Dropout(0.3)(forward)\n\n    # Backward Conv1D (Reverse Input)\n    backward = Lambda(lambda x: tf.reverse(x, axis=[1]))(x)  # Reverse time axis\n    backward = Conv1D(filters=filters, kernel_size=3, padding='causal', dilation_rate=dilation_rate)(backward)\n    backward = BatchNormalization()(backward)\n    backward = ReLU()(backward)\n    backward = Dropout(0.3)(backward)\n    backward = Lambda(lambda x: tf.reverse(x, axis=[1]))(backward)  # Reverse back\n\n    # Merge Forward and Backward Paths\n    merged = Add()([forward, backward])\n\n    return Add()([x, merged])  # Residual Connection\n\n# Define Attention Mechanism\ndef attention_layer(x):\n    \"\"\"Self-Attention Mechanism\"\"\"\n    attention_scores = Dense(x.shape[-1], activation='softmax')(x)  # Compute attention weights\n    attention_output = Multiply()([x, attention_scores])  # Scale input by attention weights\n    return attention_output\n\n# Cross-validation setup\nkf = StratifiedKFold(n_splits=2, shuffle=True, random_state=42)\nbest_accuracy = 0\nbest_model = None\nbest_training_time = None\n\n# Cross-validation loop\nwith tqdm(total=kf.get_n_splits(), desc=\"Running Cross-Validation\", unit=\"split\") as pbar:\n    for train_index, val_index in kf.split(X_train, y_train):\n        X_tr, X_val = X_train[train_index], X_train[val_index]\n        y_tr, y_val = y_train[train_index], y_train[val_index]\n\n        # Define Bi-TCN Model with Attention Mechanism\n        input_layer = Input(shape=(X_train.shape[1], 1))\n        \n        # Bi-TCN Residual Blocks with Dilated Convolutions\n        res_block1 = bi_residual_block(input_layer, filters=64, dilation_rate=1)\n        res_block2 = bi_residual_block(res_block1, filters=64, dilation_rate=2)\n        res_block3 = bi_residual_block(res_block2, filters=64, dilation_rate=4)\n\n        # Attention Mechanism\n        attention_output = attention_layer(res_block3)\n\n        flatten = Flatten()(attention_output)\n        dense1 = Dense(128, activation='relu')(flatten)\n        dropout2 = Dropout(0.3)(dense1)\n        output_layer = Dense(len(np.unique(y)), activation='softmax')(dropout2)\n\n        model = Model(inputs=input_layer, outputs=output_layer)\n        model.compile(optimizer=Adam(learning_rate=0.001), loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n\n        # Train the model and track training time\n        start_train_time = time.time()\n        history = model.fit(X_tr, y_tr, epochs=20, batch_size=32, validation_data=(X_val, y_val), verbose=0)\n        training_time = time.time() - start_train_time\n\n        # Evaluate the model\n        val_accuracy = model.evaluate(X_val, y_val, verbose=0)[1]\n        if val_accuracy > best_accuracy:\n            best_accuracy = val_accuracy\n            best_model = model\n            best_training_time = training_time\n\n        pbar.update(1)  # Update progress bar\n\n# Evaluate the best model\nstart_time = time.time()\ny_pred_prob = best_model.predict(X_test)\ninference_time = time.time() - start_time\ny_pred = np.argmax(y_pred_prob, axis=1)\n\n# Metrics Calculation\naccuracy = accuracy_score(y_test, y_pred)\nprecision = precision_score(y_test, y_pred, average='weighted')\nrecall = recall_score(y_test, y_pred, average='weighted')\nf1 = f1_score(y_test, y_pred, average='weighted')\ncm = confusion_matrix(y_test, y_pred)\nroc_auc = roc_auc_score(tf.keras.utils.to_categorical(y_test), y_pred_prob, multi_class='ovr')\n\n# Specificity Calculation\nspecificity = np.mean(np.diag(cm) / np.sum(cm, axis=1))\n\nprint(\"\\nBest Model Architecture Summary:\")\nbest_model.summary()\n\n# Function to print clean model summary with renumbered layers\ndef print_renumbered_model_summary(model):\n    print(\"\\nBest Model Architecture Summary:\")\n    print(f\"{'Layer Type':<25}{'Output Shape':<30}{'Param #':<15}\")\n    print(\"=\" * 75)\n\n    layer_counts = {}  # Dictionary to track the count of each layer type\n\n    for layer in model.layers:\n        layer_type = layer.__class__.__name__  # Get layer type\n        output_shape = str(layer.output_shape) if hasattr(layer, 'output_shape') else \"N/A\"\n        param_count = layer.count_params() if hasattr(layer, 'count_params') else 0\n\n        # Track counts and rename layer type\n        if layer_type not in layer_counts:\n            layer_counts[layer_type] = 1\n        else:\n            layer_counts[layer_type] += 1\n\n        renamed_layer = f\"{layer_type.lower()}_{layer_counts[layer_type]}\"  # Format: conv1d_1, conv1d_2, etc.\n\n        print(f\"{renamed_layer:<25}{output_shape:<30}{param_count:<15}\")\n\n# Print renumbered model summary\nprint_renumbered_model_summary(best_model)\nprint(\"----------------------------------------------\")\n\n# Print Metrics\nprint(f\"Number of features used for model training: {num_features}\")\nprint(f\"Model Test Accuracy: {accuracy:.4f}\")\nprint(f\"Precision: {precision:.4f}\")\nprint(f\"Recall (Sensitivity): {recall:.4f}\")\nprint(f\"Specificity: {specificity:.4f}\")\nprint(f\"F1-Score: {f1:.4f}\")\nprint(f\"ROC AUC: {roc_auc:.4f}\")\nprint(f\"Training Time (Best Model): {best_training_time:.2f} seconds\")\nprint(f\"Inference Time: {inference_time:.2f} seconds\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-27T06:50:40.530581Z","iopub.execute_input":"2025-02-27T06:50:40.530940Z","iopub.status.idle":"2025-02-27T06:52:02.450259Z","shell.execute_reply.started":"2025-02-27T06:50:40.530910Z","shell.execute_reply":"2025-02-27T06:52:02.449415Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import matplotlib.pyplot as plt\nplt.style.use('default')\n# Plot training & validation accuracy values\nplt.figure(figsize=(12, 5))\n\nplt.subplot(1, 2, 1)\nplt.plot(history.history['accuracy'], label='Train Accuracy', color='blue')\nplt.plot(history.history['val_accuracy'], label='Validation Accuracy', color='red')\nplt.xlabel('Epochs')\nplt.ylabel('Accuracy')\nplt.title('Model Accuracy')\nplt.legend()\nplt.grid(True, linestyle='--', alpha=0.5)\n\n# Plot training & validation loss values\nplt.subplot(1, 2, 2)\nplt.plot(history.history['loss'], label='Train Loss', color='blue')\nplt.plot(history.history['val_loss'], label='Validation Loss', color='red')\nplt.xlabel('Epochs')\nplt.ylabel('Loss')\nplt.title('Model Loss')\nplt.legend()\nplt.grid(True, linestyle='--', alpha=0.5)\n\n# Add text below the graph\nplt.figtext(0.5, -0.09, \"Accuracy & Loss Graph for Bi-TCN + AM\", ha=\"center\", fontsize=12)\n\nplt.show()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-27T06:56:53.105405Z","iopub.execute_input":"2025-02-27T06:56:53.105691Z","iopub.status.idle":"2025-02-27T06:56:53.507496Z","shell.execute_reply.started":"2025-02-27T06:56:53.105670Z","shell.execute_reply":"2025-02-27T06:56:53.506565Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from graphviz import Digraph\nfrom IPython.display import Image\n\ndef visualize_bi_tcn_attention_model():\n    dot = Digraph(format='png')\n    dot.attr(rankdir='LR') \n    # Input layer\n    dot.node('Input', 'Input Layer\\n(150, 1)', shape='box', style='filled', fillcolor='lightblue')\n    \n    # Bidirectional Residual Blocks\n    dot.node('RB1', 'Bi-Residual Block 1\\n(64 filters, d=1)', shape='box', style='filled', fillcolor='lightcoral')\n    dot.node('RB2', 'Bi-Residual Block 2\\n(64 filters, d=2)', shape='box', style='filled', fillcolor='lightcoral')\n    dot.node('RB3', 'Bi-Residual Block 3\\n(64 filters, d=4)', shape='box', style='filled', fillcolor='lightcoral')\n    \n    # Attention Mechanism\n    dot.node('Attn', 'Attention Mechanism', shape='diamond', style='filled', fillcolor='gold')\n    \n    # Fully Connected Layers\n    dot.node('Flatten', 'Flatten', shape='box', style='filled', fillcolor='lightgreen')\n    dot.node('Dense1', 'Dense 128 (ReLU)', shape='box', style='filled', fillcolor='lightgreen')\n    dot.node('Dropout', 'Dropout (0.3)', shape='box', style='filled', fillcolor='lightgrey')\n    dot.node('Output', 'Output Layer\\nDense + Softmax', shape='box', style='filled', fillcolor='lightblue')\n    \n    # Edges\n    dot.edge('Input', 'RB1')\n    dot.edge('RB1', 'RB2')\n    dot.edge('RB2', 'RB3')\n    dot.edge('RB3', 'Attn')\n    dot.edge('Attn', 'Flatten')\n    dot.edge('Flatten', 'Dense1')\n    dot.edge('Dense1', 'Dropout')\n    dot.edge('Dropout', 'Output')\n    \n    return dot\n\n# Render and visualize the model\nbi_tcn_attention_diagram = visualize_bi_tcn_attention_model()\nbi_tcn_attention_diagram.render('bi_tcn_attention_model', view=True)\nbi_tcn_attention_diagram\n# Render and save the model architecture as a PNG file\nmodel_diagram = visualize_bi_tcn_attention_model()\nmodel_diagram.render('bi_tcn_model', format='png', cleanup=False)  # Save as PNG\n\n# âœ… Display the saved image\nImage(filename='bi_tcn_model.png')\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-27T13:06:30.976620Z","iopub.execute_input":"2025-02-27T13:06:30.977010Z","iopub.status.idle":"2025-02-27T13:06:31.064378Z","shell.execute_reply.started":"2025-02-27T13:06:30.976982Z","shell.execute_reply":"2025-02-27T13:06:31.063516Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"Number of features used for model training: 150\nModel Test Accuracy: 0.9840\nPrecision: 0.9840\nRecall (Sensitivity): 0.9840\nSpecificity: 0.9846\nF1-Score: 0.9840\nROC AUC: 0.9995\nTraining Time (Best Model): 44.59 seconds\nInference Time: 1.98 seconds","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-27T06:50:27.426563Z","iopub.status.idle":"2025-02-27T06:50:27.426980Z","shell.execute_reply":"2025-02-27T06:50:27.426790Z"}},"outputs":[],"execution_count":null}]}